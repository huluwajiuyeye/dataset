<img width="984" height="873" alt="image" src="https://github.com/user-attachments/assets/7523057f-22da-487b-aa1c-0a2e1f756a44" />

  As shown in the figure, the visual representation of rainy - day images is affected by multiple factors such as imaging parameters, environmental conditions, and physical media, exhibiting a high degree of dynamism and scene specificity. There are very few reference objects on the water, and the rainfall characteristics are quite inconspicuous. Considering that synthetic data usually generates rain streaks based on static original images and cannot simulate the dynamic and complex actual conditions on the water, to improve data reliability, this model entirely uses rainy - day datasets from real scenes. We have constructed a large - scale real surveillance image dataset: self-collected shipborne camera data, land-based camera data, and screened public datasets strongly associated with real rainy day scenarios.
  
  Shipborne Camera Data. his dataset was provided by Shanghai Maili Shipping Technology Co., Ltd. A total of approximately 100 ships were used for data collection, and the data was classified by scenario and time period to ensure that consecutive frames from the same time period did not cross the training, validation, and test sets, thus preventing data leakage. The cameras for data collection were installed at the central axis position on the upper deck of the bridge, with the lens facing the bow at a slight downward angle. This setup not only ensures a wide field of view but also guarantees a relatively uniform direction of rainwater flow, covering a surrounding sea area of 50-200 meters. The data collection period spanned from August 13, 2024, to August 13, 2025, covering different waterway types in the Yangtze River Basin and coastal areas of eastern China. It included typical ship navigation states such as cruising, anchoring, and berthing, as well as diverse environmental and lighting conditions such as sunny, cloudy, and rainy days, comprehensively recording real maritime scenarios.
  
  To acquire more visual data on rain intensity for supporting the training of the rain intensity classification model, we established an on-land experimental platform, which includes rooftop cameras installed on buildings and unmanned aerial vehicles for cruise imaging. Real-time labeling of rain intensity levels was conducted based on data from tipping-bucket rain gauges and piezoelectric rain gauges. Data collection was carried out continuously for six months, spanning from March to August 2025. This platform covers diverse land-based scenarios, including urban residential areas, suburban open spaces, and river adjacent regions, thereby ensuring the dataset’s representativeness for different land-based environmental backgrounds.

  RealRain, which is sourced from a GitHub repository. It integrates rainy-day datasets from published papers, including Rain800, Rain100, SPA, RID/RIS, SPAC, D3R, and AAU. Additionally, it includes data independently collected by the authors from the Internet and several images captured in real scenarios using a SONY a6400 camera. MWD, an outdoor weather image dataset released by Gbeminiyi Ajayi on Mendeley Data, covers four weather scenarios: Cloudy, Rain, Sunny, and Sunrise. Both datasets are used for data augmentation to enhance the diversity of model training data.

  The division of rain intensity levels strictly follows Short-term Meteorological Service Rainfall Grades, and the annotation process adopts the mechanism of "local meteorological data + rain gauge data + AIS data + independent annotation by three experts + majority voting". For no rain scenarios, representative frames are selected from long-term collected images, covering conditions such as sunny, cloudy, and foggy days; for rainy samples, continuous frame sampling is performed to ensure that frames from the same video sequence remain in the same set, with images covering different intensities from light rain to heavy rain. The sampling frequency is designed to balance scene diversity and sufficiency of rainy-day samples: one frame is captured every 30 minutes during regular periods, while the frequency is shortened to one frame every 60 seconds when rainfall occurs, so as to ensure capturing a sufficient number of rainy-day images. All training data undergo re-screening to remove indistinguishable invalid segments, thus ensuring the accuracy and objectivity of annotation results.

  We developed two large-scale datasets of real-world shipborne surveillance images: a binary dataset and a four-level rain-intensity dataset comprising No Rain, Light, Medium, and Heavy. Image data were collected from 100 ships and partitioned jointly by scene and time period. To avoid leakage, consecutive frames from the same time block were never split across the training, validation, and test sets. The hardware consisted of on-board surveillance cameras mounted on the vessels, which captured real-time scenes during navigation. The dataset includes images of rain and no-rain days captured in various environments. Figure shows examples of rain and no-rain samples in the dataset.All videos first underwent manual screening to remove invalid segments such as lens obstruction and equipment failures, ensuring a clean dataset.

  For the binary dataset,details of which are shown in Table 1, data collection spanned 13 Aug 2024 to 20 Apr 2025 and covered multiple waterway types in the Yangtze River Basin and along China’s eastern coasts, as well as diverse navigation states including cruising, berthing, and docking. The corpus included sunny, cloudy, foggy, and rainy conditions. Positive and negative samples were strictly balanced at approximately 50% each, yielding 24,609 images. Static frames were extracted at 60-second intervals and stored on a cloud server. For no-rain scenes, we selected representative frames from long-term collections under clear or cloudy weather. For rain scenes, continuous frame sampling was adopted to ensure that frames from the same video sequence remained in the same set; these images covered different rain intensities ranging from light rain to heavy rain, without further labeling of fine-grained levels.
Labels were produced by integrating rainfall records from meteorological stations, expert visual inspection, and ship-trajectory logs obtained via HiFleet AIS vessel-tracking platform, which together ensured labeling accuracy.

<img width="1167" height="372" alt="image" src="https://github.com/user-attachments/assets/bd48fca0-f862-4118-80f0-9258df9d7555" />

Data collection for the four-class rain intensity dataset,details of which are shown in Table 2,spanned from April 21, 2024 to August 13, 2025. Although this dataset was sourced from the same shipborne cameras as the binary classification dataset, more stringent screening was applied during labeling due to the requirement for fine-grained rain intensity grading, resulting in a scarcer number of valid samples. To supplement the data volume, an additional experimental platform was built on land, including locations such as building rooftops and the Nantong UAV depot. Image labeling was completed by referencing data from tipping bucket rain gauges, rain gauges at the DJI UAV depot, as well as historical ship trajectories and meteorological data.The sampling frequency was designed to balance scenario diversity and sufficient rainy samples: one frame was collected every 30 minutes during regular periods, while the frequency was shortened to one frame every 60 seconds when rainfall occurred. This approach ensured the capture of an adequate number of rainy images.

<img width="1169" height="449" alt="image" src="https://github.com/user-attachments/assets/f1923b69-83f9-47e1-8aeb-f7568f36685c" />

  The classification of rain intensity levels strictly refers to the Short-Term Meteorological Service Rainfall Intensity Grades,with details shown in Table 3. For the labeling process, a mechanism of independent labeling by three experts plus majority voting was adopted: each image was labeled separately by three experts, and the final label was determined based on the majority opinion. This approach ensured the accuracy and objectivity of the labeling results.

<img width="1174" height="421" alt="image" src="https://github.com/user-attachments/assets/3af81441-b91a-4cd2-b8ae-05b4e6d28756" />

  A significant sample imbalance exists in the four-class dataset, influenced by the occurrence frequency and intensity distribution of actual rainfall events. Rain-free samples account for the highest proportion at approximately 42.41%, followed by light rain samples at around 28.98%, moderate rain samples at 20.76%, and heavy rain samples at the lowest share of only about 7.85%.In particular, heavy rain samples are significantly insufficient due to their low natural occurrence frequency. Direct training with such imbalanced data would easily limit the model’s accuracy in recognizing rain intensity. Therefore, a transfer learning strategy was adopted in subsequent work to fully utilize data features and improve the accuracy of rain intensity recognition.








Due to copyright restrictions, only part of the data is displayed. For detailed data, please contact:202430410030@stu.shmtu.edu.cn

